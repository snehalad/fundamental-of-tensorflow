{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehalad/fundamentals-of-tensorflow/blob/main/neural_network_classification_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQlz3YoYvbrv"
      },
      "source": [
        "## TensorFlow 2.7.0 input shape breaking changes\n",
        "\n",
        "If you're running [notebook 02](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/02_neural_network_classification_in_tensorflow.ipynb) of the TensorFlow Deep Learning course, you might run into some issues when working with `model_3`.\n",
        "\n",
        "When [TensorFlow 2.7.0 was released](https://github.com/tensorflow/tensorflow/releases/tag/v2.7.0) one of the major breaking changes was:\n",
        "\n",
        "> `tf.keras:`\n",
        "> * The methods `Model.fit()`, `Model.predict()`, and `Model.evaluate()` will no longer uprank input data of shape `(batch_size,)` to become `(batch_size, 1)`. This enables Model subclasses to process scalar data in their `train_step()`/`test_step()`/`predict_step()` methods.\n",
        "> Note that this change may break certain subclassed models. You can revert back to the previous behavior by adding upranking yourself in the `train_step()`/`test_step()`/`predict_step()` methods, e.g. `if x.shape.rank == 1: x = tf.expand_dims(x, axis=-1)`. Functional models as well as Sequential models built with an explicit input shape are not affected.\n",
        "\n",
        "This means that inputs with shape `(batch_size,)` won't automatically be upranked to become `(batch_size, 1)`.\n",
        "\n",
        "In notebook 02, `X_reg_train` is of shape `(150, )` which is like `(batch_size=150, )`.\n",
        "\n",
        "```python\n",
        "X_reg_train.shape\n",
        ">>> (150,)\n",
        "```\n",
        "So for the model to work we have to uprank it on the last dimension to be `(batch_size=150, 1)`:\n",
        "\n",
        "```python\n",
        "tf.expand_dims(X_reg_train, axis=1).shape\n",
        ">>> TensorShape([150, 1])\n",
        "```\n",
        "\n",
        "If you get any shape issues through the notebook and are running TensorFlow 2.7.0 this is likely one of the causes.\n",
        "\n",
        "See more in this GitHub discussion: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/278 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzkQ44V3vnW5"
      },
      "source": [
        "## Before with `tf.keras.losses.BinaryCrossentropy()` (errors after TensorFlow 2.7.0)\n",
        "\n",
        "You'll see something like: \n",
        "\n",
        "```\n",
        "ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n",
        "    \n",
        "    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n",
        "    \n",
        "    Call arguments received:\n",
        "      • inputs=tf.Tensor(shape=(None,), dtype=int64)\n",
        "      • training=True\n",
        "      • mask=None\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7QMSj7qwSpV",
        "outputId": "257968ae-d52a-4c28-8dd0-ed44550d1bfe"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ7cAMsEwGb8"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create some regression data\n",
        "X_regression = np.arange(0, 1000, 5)\n",
        "y_regression = np.arange(100, 1100, 5)\n",
        "\n",
        "# Split it into training and test sets\n",
        "X_reg_train = X_regression[:150]\n",
        "X_reg_test = X_regression[150:]\n",
        "y_reg_train = y_regression[:150]\n",
        "y_reg_test = y_regression[150:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "ANdSya8hvrvp",
        "outputId": "fa5ce58e-7fc2-47c9-ca7d-98adb9f86dec"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (this time 3 layers)\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100), # add 100 dense neurons\n",
        "  tf.keras.layers.Dense(10), # add another layer with 10 neurons\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(), # use Adam instead of SGD\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit our model to the data\n",
        "model_3.fit(X_reg_train, y_reg_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-435c034b6928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 3. Fit our model to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_reg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_reg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=int64)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTaeG80vvpFA"
      },
      "source": [
        "## After with `tf.keras.losses.BinaryCrossentropy()` (no error)\n",
        "\n",
        "The two main fixes here are:\n",
        "1. Explicitly define the input shape to the model with `input_shape=(None, 1)`.\n",
        "2. Expand the dimensions of the input to `model.fit()` with `tf.expand_dims(x, axis=-1)` (where `x` is the variable you're fitting on)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSE1Dmq5vPkf",
        "outputId": "9cdf390a-e832-4002-94ac-d1f79d2ac930"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (this time 3 layers)\n",
        "model_3 = tf.keras.Sequential([\n",
        "  # Before TensorFlow 2.7.0\n",
        "  # tf.keras.layers.Dense(100), # add 100 dense neurons\n",
        "\n",
        "  ## After TensorFlow 2.7.0 ## \n",
        "  tf.keras.layers.Dense(100, input_shape=(None, 1)), # add 100 dense neurons with input_shape defined (None, 1) = look at 1 sample at a time\n",
        "  tf.keras.layers.Dense(10), # add another layer with 10 neurons\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(), # use Adam instead of SGD\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 3. Fit our model to the data\n",
        "model_3.fit(tf.expand_dims(X_reg_train, axis=-1), # <- expand dimension on final axis \n",
        "            y_reg_train, \n",
        "            epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 1s 4ms/step - loss: -7092.2158 - accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -7090.2983 - accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -7102.5044 - accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: -7091.4810 - accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: -7102.2798 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc888f6d2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKwEoeXKvqOa"
      },
      "source": [
        "## Before with `tf.keras.losses.mae` (errors after TensorFlow 2.7.0)\n",
        "\n",
        "You'll see the same issue if you're using MAE as a loss function.\n",
        "\n",
        "It's back to the input data.\n",
        "\n",
        "Does it satisfy the new requirement of being `(batch_size, 1)`? Or not?\n",
        "\n",
        "Remember one of the most common issues with TensorFlow and deep learning is input and output shapes. \n",
        "\n",
        "Run this code below and you'll see an error like:\n",
        "\n",
        "```\n",
        "ValueError: Exception encountered when calling layer \"sequential\" (type Sequential).\n",
        "    \n",
        "    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n",
        "    \n",
        "    Call arguments received:\n",
        "      • inputs=tf.Tensor(shape=(None,), dtype=int64)\n",
        "      • training=True\n",
        "      • mask=None\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "rRXwWtLJxzbe",
        "outputId": "bd6d899b-d628-49d9-f2e5-0ac37e2e9064"
      },
      "source": [
        "# Setup random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Recreate the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Change the loss and metrics of our compiled model\n",
        "model_3.compile(loss=tf.keras.losses.mae, # change the loss function to be regression-specific\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['mae']) # change the metric to be regression-specific\n",
        "\n",
        "# Fit the recompiled model\n",
        "model_3.fit(X_reg_train, \n",
        "            y_reg_train, \n",
        "            epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-399c30ff37d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m model_3.fit(X_reg_train, \n\u001b[1;32m     18\u001b[0m             \u001b[0my_reg_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             epochs=5)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" (type Sequential).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=int64)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnwyWKGVx6Bl"
      },
      "source": [
        "## After with `tf.keras.losses.mae` (no error)\n",
        "\n",
        "The fix comes in the input to `model.fit()`.\n",
        "\n",
        "The input was previously `X_reg_train`, now it's going to be `tf.expand_dims(X_reg_train, axis=-1)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzzvrjsMyLdl",
        "outputId": "c7c10f2c-7cd0-4e97-ed2c-d557c1428b74"
      },
      "source": [
        "# Setup random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Recreate the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Change the loss and metrics of our compiled model\n",
        "model_3.compile(loss=tf.keras.losses.mae, # change the loss function to be regression-specific\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['mae']) # change the metric to be regression-specific\n",
        "\n",
        "# Fit the recompiled model\n",
        "model_3.fit(tf.expand_dims(X_reg_train, axis=-1), # <- Expand the final dimension of the input \n",
        "            y_reg_train, \n",
        "            epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 248.2155 - mae: 248.2155\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 138.9005 - mae: 138.9005\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 53.1039 - mae: 53.1039\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 73.5170 - mae: 73.5170\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 71.2358 - mae: 71.2358\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc8899619d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM-aGm1fyRGx"
      },
      "source": [
        "## Why this happens\n",
        "\n",
        "This happens because `model.fit()` no longer upranks single dimension tensors from `(batch_size, )` to `(batch_size, 1)`.\n",
        "\n",
        "So we either have to:\n",
        "* Do it ourselves with `tf.expand_dims()`\n",
        "* Define the `input_shape` to the model\n",
        "\n",
        "Both of these were seen above.\n",
        "\n",
        "To illustrate once more, let's check the dimensions of the input data `X_reg_train`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvJmnFYxyeJW",
        "outputId": "c0c2bc7e-3bdf-468f-d90a-329a1e3f4746"
      },
      "source": [
        "# Original input dimensions\n",
        "X_reg_train.ndim, X_reg_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, (150,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16j_vgaey6Bd",
        "outputId": "92d6da3b-7123-495d-e439-49c70e5aa096"
      },
      "source": [
        "# Upranked input dimensions\n",
        "tf.expand_dims(X_reg_train, axis=-1).ndim, tf.expand_dims(X_reg_train, axis=-1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, TensorShape([150, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}